{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNN:\n",
    "\n",
    "  def __init__(self,K=3,weight_gist= 0.85/(0.85+0.75)):\n",
    "    self.weight_gist = weight_gist\n",
    "    self.K = K\n",
    "    pass\n",
    "\n",
    "  \"\"\"fit: normalized后输入, 输入变量都化成list(np.ndarray)\"\"\"\n",
    "  def fit(self,training_gist_set,training_hough_set,training_y):\n",
    "    self.training_gist_set = training_gist_set\n",
    "    self.training_hough_set = training_hough_set\n",
    "    self.training_y = training_y\n",
    "  \n",
    "  def computeDistance(self,training_gist_v,training_hough_v,target_gist_vector,target_hough_vector):\n",
    "    diff1 = np.sum((training_gist_v-target_gist_vector) ** 2) ** 0.5\n",
    "    diff2 = np.sum((training_hough_v-target_hough_vector) ** 2) ** 0.5\n",
    "    # diff2 = np.linalg.norm(training_hough_v-target_hough_vector,'L2')\n",
    "    dis = self.weight_gist*diff1 + (1-self.weight_gist)*diff2\n",
    "    return dis\n",
    "\n",
    "  def getNeighbor(self,target_gist_vector,target_hough_vector):\n",
    "    sample_dis_to_train = np.zeros(shape=len(self.training_gist_set))\n",
    "    for i in range(0,len(self.training_gist_set)):\n",
    "      sample_dis_to_train[i] = self.computeDistance(training_gist_v=self.training_gist_set[i],training_hough_v=self.training_hough_set[i],target_gist_vector=target_gist_vector,target_hough_vector=target_hough_vector)\n",
    "    \n",
    "    K_index = np.argsort(sample_dis_to_train,kind='stable')[:self.K]\n",
    "    neighbors = self.training_y[K_index]\n",
    "    return neighbors\n",
    "\n",
    "  def majority(self, neighbors):\n",
    "    b = np.bincount(neighbors)\n",
    "    return np.argmax(b)\n",
    "\n",
    "  def predict(self,target_gist_set,target_hough_set):\n",
    "    target_predictions = []\n",
    "    for i in range(0,len(target_gist_set)):\n",
    "      ns = self.getNeighbor(target_gist_vector=target_gist_set[i],target_hough_vector=target_hough_set[i])\n",
    "      res = self.majority(neighbors=ns)\n",
    "      target_predictions.append(res)\n",
    "    return target_predictions\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GistUtils:\n",
    "    def __init__(self, n_resize=128, n_w=5, ln_orientation=[8, 8, 8, 8], n_block_num=4, n_prefilt=4):\n",
    "        # vector dim(single chanle) = sum(ln_orientation) * n_block_num * n_block_num\n",
    "        # (8+8+8+8)*(4*4) = 512\n",
    "        self.n_resize = n_resize\n",
    "        self.n_boundaryExtension = self.n_resize // 4\n",
    "        self.n_w = n_w    \n",
    "        self.ln_orientation = ln_orientation\n",
    "        self.n_block_num = n_block_num  # MUST n_resize % n_block_num == 0\n",
    "        self.n_prefilt = n_prefilt\n",
    "             \n",
    "        self.__create_gabor()\n",
    "        self.__get_gfmat()\n",
    "        \n",
    "    def get_gist_vec(self, np_img_raw, mode=\"rgb\"):\n",
    "        # resize \n",
    "        np_img_resize, n_ret = img_resize(np_img_raw, (self.n_resize, self.n_resize))\n",
    "        if n_ret != 0:\n",
    "            print(\"image resize error\")\n",
    "            return None\n",
    "\n",
    "        # convert gray or rgb\n",
    "        np_gist = None\n",
    "        if mode.lower() == \"gray\":\n",
    "            np_img_gray, n_ret = img_2gray(np_img_resize)\n",
    "            np_prefilt_img = self.__get_pre_filt(np_img_gray)\n",
    "            np_gist = self.__gist_main(np_prefilt_img)\n",
    "\n",
    "        elif mode.lower() == \"rgb\" or mode.lower() == \"bgr\":\n",
    "            np_img_bgr, n_ret = img_2bgr(np_img_resize)\n",
    "            \n",
    "            np_img_b = np_img_bgr[:,:,0]\n",
    "            np_img_g = np_img_bgr[:,:,1]\n",
    "            np_img_r = np_img_bgr[:,:,2]\n",
    "\n",
    "            np_gist_b = self.__get_pre_filt(np_img_b)\n",
    "            np_gist_g = self.__get_pre_filt(np_img_g)\n",
    "            np_gist_r = self.__get_pre_filt(np_img_r)\n",
    "\n",
    "            np_gist_b = self.__gist_main(np_gist_b)\n",
    "            np_gist_g = self.__gist_main(np_gist_g)\n",
    "            np_gist_r = self.__gist_main(np_gist_r)\n",
    "\n",
    "\n",
    "            np_gist = np.hstack([np_gist_b, np_gist_g, np_gist_r])\n",
    "        else:\n",
    "            print(\"input mode error\")\n",
    "        \n",
    "        return np_gist\n",
    "    \n",
    "    def __get_pre_filt(self, np_img): \n",
    "        np_log_img = np.log(np_img + 1.0)\n",
    "        np_pad_img = np.pad(np_log_img,((self.n_w,self.n_w), (self.n_w,self.n_w)), 'symmetric')\n",
    "\n",
    "        np_gf = self.np_gf\n",
    "        np_out = np_pad_img - np.real(np.fft.ifft2(np.fft.fft2(np_pad_img) * np_gf ))\n",
    "        \n",
    "        np_local = np.sqrt(np.abs(np.fft.ifft2(np.fft.fft2(np_out **2) * np_gf)))\n",
    "        np_out = np_out / (0.2 + np_local)\n",
    "        \n",
    "        n_size = self.n_resize + 2 * self.n_w\n",
    "        \n",
    "        return np_out[self.n_w: n_size - self.n_w, self.n_w : n_size - self.n_w]\n",
    "    \n",
    "    def __gist_main(self, np_prefilt_img):\n",
    "        \n",
    "        n_b = self.n_boundaryExtension\n",
    "        np_pad_img = np.pad(np_prefilt_img, ((n_b, n_b), (n_b, n_b)), 'symmetric')\n",
    "        np_fft2_img = np.fft.fft2(np_pad_img)\n",
    "        \n",
    "    \n",
    "        n_filter = self.np_gabor.shape[2]      \n",
    "        n_size = self.np_gabor.shape[0]\n",
    "        lf_gist = []\n",
    "        for i in range(n_filter):\n",
    "            np_res = np.abs(np.fft.ifft2( np_fft2_img * self.np_gabor[:,:,i] ))\n",
    "            \n",
    "            np_res = np_res[n_b: n_size - n_b, n_b : n_size - n_b]\n",
    "            \n",
    "            lf_filter_res = self.__down_sampling(np_res)      \n",
    "            lf_gist = lf_gist + lf_filter_res\n",
    "        \n",
    "        np_gist = np.asarray(lf_gist)\n",
    "        return np_gist[np.newaxis,:]\n",
    "    \n",
    "    def __create_gabor(self):\n",
    "        n_gabor_size = self.n_resize + 2 * self.n_boundaryExtension\n",
    "        ln_or = self.ln_orientation\n",
    "        \n",
    "        n_scales = len(ln_or)\n",
    "        n_filters = sum(ln_or)\n",
    "        \n",
    "        np_param = np.zeros((n_filters, 4), dtype = np.float64)\n",
    "        n_index = 0\n",
    "        for i in range(n_scales):\n",
    "            for j in range(0, ln_or[i]):\n",
    "                np_param[n_index, 0] = 0.35\n",
    "                np_param[n_index, 1] = 0.3 / (1.85**i)\n",
    "                np_param[n_index, 2] = 16 *(ln_or[i]**2)/(32**2)\n",
    "                np_param[n_index, 3] = np.pi/ln_or[i] * j\n",
    "                \n",
    "                n_index += 1\n",
    "         \n",
    "     \n",
    "        np_linear = np.linspace(-n_gabor_size//2, n_gabor_size//2-1, n_gabor_size)\n",
    "        np_fx, np_fy = np.meshgrid(np_linear, np_linear)\n",
    "        np_res_A = np.fft.fftshift(np.sqrt(np_fx ** 2 + np_fy**2))\n",
    "        np_res_B = np.fft.fftshift(np.angle(np_fx + 1j*np_fy))\n",
    "        \n",
    "        self.np_gabor = np.zeros((n_gabor_size, n_gabor_size, n_filters), dtype = np.float64)\n",
    "        for i in range(n_filters):\n",
    "            np_tr = np_res_B + np_param[i,3]\n",
    "            np_A  = (np_tr < -np.pi) + 0.0\n",
    "            np_B  = (np_tr > np.pi) + 0.0\n",
    "            \n",
    "            np_tr = np_tr + 2 *np.pi * np_A - 2*np.pi*np_B\n",
    "            np_every_gabor = np.exp(-10 * np_param[i,0] * ((np_res_A / n_gabor_size /np_param[i,1] - 1) **2) - 2*np_param[i,2]*np.pi*(np_tr **2))\n",
    "            \n",
    "            self.np_gabor[:,:,i] = np_every_gabor\n",
    "            \n",
    "            \n",
    "    \n",
    "    def __get_gfmat(self):\n",
    "        n_s1 = self.n_prefilt /np.sqrt(np.log(2))\n",
    "        n_boundray = self.n_resize + 2 * self.n_w\n",
    "         \n",
    "        np_linear = np.linspace(-n_boundray//2, n_boundray//2-1, n_boundray)\n",
    "        np_fx, np_fy = np.meshgrid(np_linear, np_linear)\n",
    "        \n",
    "#        np_gf = np.fft.fftshift(np.exp( -(np_fx **2 + np_fy **2)/(n_s1 ** 2)))\n",
    "        self.np_gf = np.fft.fftshift(np.exp( -(np_fx **2 + np_fy **2)/(n_s1 ** 2)))\n",
    "           \n",
    "    def __down_sampling(self, np_img):\n",
    "        np_index = np.linspace(0, self.n_resize, self.n_block_num + 1, dtype = np.int)\n",
    "        ln_data = []\n",
    "        for i in range(self.n_block_num):\n",
    "            for j in range(self.n_block_num):\n",
    "                np_zone = np_img[np_index[i]: np_index[i+1] , np_index[j]: np_index[j+1]]\n",
    "                np_zone = np_zone.T.reshape(-1)\n",
    "#                n_res = np.median(np_zone)\n",
    "                n_res = np.max(np_zone)\n",
    "                ln_data.append(n_res)\n",
    "        return ln_data\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def img_2bgr(np_img_in, run_log=None, b_print=False):\n",
    "    if np_img_in is None:\n",
    "        return None, -3 \n",
    "\n",
    "    np_img_bgr = None # if raw image is uint16 so conver to uint8 \n",
    "    if len(np_img_in.shape) == 3 and np_img_in.shape[2] == 3: # Raw Image is BGR imge, so continue\n",
    "        np_img_bgr = np_img_in\n",
    "    elif len(np_img_in.shape) == 3 and np_img_in.shape[2] == 4: # Raw Image is BGRA imge, there are different situation to solve\n",
    "        h, w, c = np_img_in.shape\n",
    "        np_img_bgr_1 = cv2.cvtColor(np_img_in, cv2.COLOR_BGRA2BGR)    \n",
    "        b, g, r, a = cv2.split(np_img_in)\n",
    "        b = cv2.convertScaleAbs(b, alpha=(255.0/65535.0)) # (b/256).astype('uint8')\n",
    "        g = cv2.convertScaleAbs(g, alpha=(255.0/65535.0))\n",
    "        r = cv2.convertScaleAbs(r, alpha=(255.0/65535.0))\n",
    "        a = cv2.convertScaleAbs(a, alpha=(255.0/65535.0))\n",
    "        new_img  = cv2.merge((b, g, r))\n",
    "        not_a = cv2.bitwise_not(a)\n",
    "        not_a = cv2.cvtColor(not_a, cv2.COLOR_GRAY2BGR) \n",
    "        new_img = cv2.bitwise_and(new_img, new_img, mask = a)\n",
    "        np_img_bgr_2 = cv2.add(new_img, not_a) \n",
    "        np_img_gray_1 = cv2.cvtColor(cv2.convertScaleAbs(np_img_bgr_1, alpha=(255.0/65535.0)), cv2.COLOR_BGR2GRAY) # Which image has most not white\n",
    "        np_img_gray_2 = cv2.cvtColor(np_img_bgr_2, cv2.COLOR_BGR2GRAY)\n",
    "        n_info_1 = len(np.unique(np_img_gray_1))\n",
    "        n_info_2 = len(np.unique(np_img_gray_2))    \n",
    "        np_img_bgr = np_img_bgr_1 if n_info_1 >= n_info_2 else np_img_bgr_2\n",
    "    elif len(np_img_in.shape) == 3 and np_img_in.shape[2] == 1: # Raw Image is gray image\n",
    "        np_img_bgr = np.tile(np_img_in, (1, 1, 3))     # 256x256x1 ==> 256x256x3\n",
    "    elif len(np_img_in.shape) == 2:\n",
    "        np_img_bgr = np.tile(np_img_in, (3, 1, 1))     # 256x256 ==> 3x256x256\n",
    "        np_img_bgr = np.transpose(np_img_bgr, (1, 2, 0))  # 3x256x256 ==> 256x256x3\n",
    "    return np_img_bgr, 0\n",
    "    \n",
    "''' \n",
    "Convert raw image to small gray image, resize is  n_resize * n_resize \n",
    "''' \n",
    "def img_2gray(np_img_raw, run_log=None, b_print=False):\n",
    "    if np_img_raw is None:\n",
    "        s_msg = \"input image null\"\n",
    "        run_log and run_log.error(s_msg)\n",
    "        b_print and print(s_msg)\n",
    "        return None, -3\n",
    "    np_img_gray = None # Raw Image is BGR imge, so convert rgb to gray\n",
    "    if len(np_img_raw.shape) == 3 and np_img_raw.shape[2] == 3:\n",
    "        np_img_gray = cv2.cvtColor(np_img_raw, cv2.COLOR_BGR2GRAY) \n",
    "    elif len(np_img_raw.shape) == 3 and np_img_raw.shape[2] == 4: # Raw Image is BGRA imge, there are different situation to solve\n",
    "        n_sence = 3\n",
    "        np_img_gray_choose = np.zeros([np_img_raw.shape[0], np_img_raw.shape[1], n_sence], dtype=np.uint8)\n",
    "\n",
    "        np_img_gray_choose[:, :, 0] = 255 - np_img_raw[:, :, 3]\n",
    "        np_img_gray_choose[:, :, 1] = cv2.cvtColor(np_img_raw, cv2.COLOR_BGRA2GRAY)\n",
    "        np_img_gray_choose[:, :, 2] = cv2.cvtColor(np_img_raw[:, :, 0:3], cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "        ln_sence_non0_num = [] # Get nonzero element of every resize gray\n",
    "        for i in range(n_sence):\n",
    "            ln_sence_non0_num.append(len(np_img_gray_choose[:, :, i].nonzero()[0]))  \n",
    "        if len(set(ln_sence_non0_num)) > 1: # Which image has most nonzero element\n",
    "            n_max_index = ln_sence_non0_num.index(max(ln_sence_non0_num))\n",
    "            np_img_gray = np_img_gray_choose[:, :, n_max_index]\n",
    "        else: # Which image has most different element\n",
    "            ln_diff_pix_num = []\n",
    "            for i in range(n_sence):\n",
    "                ln_diff_pix_num.append(len(np.unique(np_img_gray_choose[:, :, i])))\n",
    "            n_max_index = ln_diff_pix_num.index(max(ln_diff_pix_num))\n",
    "            np_img_gray = np_img_gray_choose[:, :, n_max_index] \n",
    "    elif len(np_img_raw.shape) == 3 and np_img_raw.shape[2] == 1: # Raw Image is gray image\n",
    "        np_img_gray = np_img_raw[:, :, 0]\n",
    "    elif len(np_img_raw.shape) == 2:\n",
    "        np_img_gray = np_img_raw\n",
    "    return np_img_gray, 0\n",
    "\n",
    "\n",
    "''' \n",
    "resize a image \n",
    "'''     \n",
    "def img_resize(np_img_in, ln_resize, run_log=None, b_print=False):\n",
    "    try:\n",
    "        np_img_resize = cv2.resize(np_img_in, ln_resize, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "        return np_img_resize, 0\n",
    "    except Exception as e:\n",
    "        s_msg = 'resize err:%s' % str(e)\n",
    "        run_log and run_log.error(s_msg)\n",
    "        b_print and print(s_msg)\n",
    "        return None, -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classificateForTarget():\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    self.gist_helper = GistUtils()\n",
    "  \n",
    "  def fit(self,X_train,y_train,K_list=[3,5,7],weight_gist = 84.2/(79.2+84.2)) -> None:\n",
    "      self.X_train = X_train\n",
    "      self.y_train = y_train\n",
    "      self.K_list = K_list\n",
    "      \n",
    "      #pre-process\n",
    "      X_train_gray_equ = []\n",
    "      X_train_equ_blur =[]\n",
    "      X_train_edge = []\n",
    "\n",
    "      #灰度直方图均衡化\n",
    "      for i in range(0,len(self.X_train)):\n",
    "        img = cv2.resize(self.X_train[i],(256,256))\n",
    "        img = self.X_train[i].astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        X_train_gray_equ.append(cv2.equalizeHist(img))\n",
    "\n",
    "      #高斯模糊\n",
    "      for i in range(0,len(X_train_gray_equ)):\n",
    "        X_train_equ_blur.append(cv2.GaussianBlur(X_train_gray_equ[i],(5,5),1.5))\n",
    "\n",
    "      #canny\n",
    "      for i in range(0,len(X_train_equ_blur)):\n",
    "        X_train_edge.append(cv2.Canny(X_train_equ_blur[i],30,100))\n",
    "\n",
    "      #prepare data for KNN train\n",
    "\n",
    "      ## hough---\n",
    "      X_train_hough = []\n",
    "      X_train_hough_len = []\n",
    "      self.th1 = 7\n",
    "      self.maxg1 = 7.4\n",
    "      self.th2 = 15\n",
    "      self.maxg2 = 20\n",
    "\n",
    "      for i in range(0,len(X_train_edge)):\n",
    "        lines = cv2.HoughLinesP(X_train_edge[i], 1, np.pi/180, self.th1, 100, self.maxg1)\n",
    "        if lines is None:\n",
    "          X_train_hough.append(0)\n",
    "        else:\n",
    "          X_train_hough.append(len(lines))\n",
    "\n",
    "        lines_for_length = cv2.HoughLinesP(X_train_edge[i], 1, np.pi/180, self.th2, 100, self.maxg2)\n",
    "        max_length = 0 #曼哈顿距离\n",
    "        if lines_for_length is not None:\n",
    "          for line in lines_for_length:\n",
    "            x1 = line[0][0]\n",
    "            y1 = line[0][1]\n",
    "            x2 = line[0][2]\n",
    "            y2 = line[0][3]\n",
    "            temp = y2-y1+x2-x1\n",
    "            if temp > max_length:\n",
    "              max_length = temp\n",
    "          \n",
    "        X_train_hough_len.append(max_length)\n",
    "\n",
    "      X_train_hough_2 = pd.DataFrame(X_train_hough,columns=['number of lines'])\n",
    "      X_train_hough_2[\"max length of line\"] = X_train_hough_len\n",
    "\n",
    "      self.minx_num = np.min(X_train_hough_2['number of lines'])\n",
    "      self.minx_len = np.min(X_train_hough_2['max length of line'])\n",
    "      self.maxx_num = np.max(X_train_hough_2['number of lines'])\n",
    "      self.maxx_len = np.max(X_train_hough_2['max length of line'])\n",
    "      \n",
    "      X_train_hough_2_ = X_train_hough_2.apply(lambda x:(x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "\n",
    "      self.X_train_hough_set = []\n",
    "      for i in range(0,len(X_train_hough)):\n",
    "        self.X_train_hough_set.append(np.array([X_train_hough_2_.iat[i,0],X_train_hough_2_.iat[i,1]]))\n",
    "\n",
    "      ## gist---\n",
    "      self.X_train_gist_ = []\n",
    "\n",
    "      for i in range(0,len(self.X_train)):\n",
    "        self.X_train_gist_.append(self.gist_helper.get_gist_vec(self.X_train[i]))\n",
    "\n",
    "      # # knn fit\n",
    "      # self.knn = MyKNN(weight_gist = 84.2/(79.2+84.2))\n",
    "      # self.knn.fit(self.X_train_gist_,self.X_train_hough_set,np.array(y_train))\n",
    "\n",
    "      self.knn_list = []\n",
    "      for i in range(0, len(K_list)):\n",
    "        knn = MyKNN(K=K_list[i],weight_gist = weight_gist)\n",
    "        knn.fit(self.X_train_gist_, self.X_train_hough_set,np.array(self.y_train))\n",
    "        self.knn_list.append(knn)\n",
    "\n",
    "  def emsemlble_knn(self):\n",
    "    pred = []\n",
    "    for i in range(0,len(self.K_list)):\n",
    "      pred_myknn = self.knn_list[i].predict(self.gist,self.hough_set)\n",
    "      pred.append(np.array(pred_myknn))\n",
    "\n",
    "    sum_pred = 0\n",
    "    for l in range(0,len(pred)):\n",
    "      sum_pred = sum_pred + pred[i]\n",
    "\n",
    "    predict = np.round(sum_pred/len(self.K_list))\n",
    "\n",
    "    return predict\n",
    "\n",
    "  def preprocess_target(self, target_img) -> None:\n",
    "      target_img1 = cv2.resize(target_img,(256,256))\n",
    "      target_img1 = cv2.cvtColor(target_img1, cv2.COLOR_RGB2GRAY)\n",
    "      target_img1 = cv2.equalizeHist(target_img1)\n",
    "      \n",
    "      blur = cv2.GaussianBlur(target_img1,(5,5),1.5)\n",
    "      edge = cv2.Canny(blur,30,100)\n",
    "\n",
    "      self.target_hough_len = 0\n",
    "      self.target_hough_num = 0\n",
    "      \n",
    "      lines = cv2.HoughLinesP(edge, 1, np.pi/180, self.th1, 100, self.maxg1)\n",
    "      if lines is not None:\n",
    "        self.target_hough_num = len(lines)\n",
    "      else:\n",
    "        self.target_hough_num = 0\n",
    "      self.target_hough_num = (self.target_hough_num - self.minx_num)/(self.maxx_num - self.maxx_num)\n",
    "\n",
    "      lines_for_length = cv2.HoughLinesP(edge, 1, np.pi/180, self.th2, 100, self.maxg2)\n",
    "      max_length = 0 \n",
    "      if lines_for_length is not None:\n",
    "        for line in lines_for_length:\n",
    "          x1 = line[0][0]\n",
    "          y1 = line[0][1]\n",
    "          x2 = line[0][2]\n",
    "          y2 = line[0][3]\n",
    "          temp = y2-y1+x2-x1\n",
    "          if temp > max_length:\n",
    "            max_length = temp\n",
    "        \n",
    "      self.target_hough_len = max_length\n",
    "      self.target_hough_len = (self.target_hough_len - self.minx_len)/(self.maxx_len - self.maxx_len)\n",
    "      \n",
    "      #final for input of KNN\n",
    "      self.hough_set = [np.array([self.target_hough_num,self.target_hough_len])]\n",
    "      self.gist = self.gist_helper.get_gist_vec(target_img)\n",
    "\n",
    "  def predict(self, target_img) -> int:\n",
    "    self.preprocess_target(target_img)\n",
    "    pred = self.emsemlble_knn()\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = classificateForTarget()\n",
    "# c.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = c.predict(X_test[8])\n",
    "# p"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
